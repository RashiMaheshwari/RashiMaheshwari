# 👋 Hi, I’m @RashiMaheshwari

Welcome to my GitHub profile! I'm a passionate **Data Engineer** with a keen interest in building efficient, scalable, and fault-tolerant data pipelines. I specialize in **ETL workflows**, **data ingestion**, **real-time analytics**, and **cloud-native technologies**. My goal is to leverage data to drive better decision-making and build systems that deliver meaningful insights.

## 🚀 What I'm Focused On

- 👀 **I’m deeply interested in**:
  - **Data Engineering**: Creating robust data pipelines, optimizing workflows, and designing scalable systems.
  - **Big Data Technologies**: Spark, Kafka, and Hadoop are some of my go-to tools for processing large datasets.
  - **Cloud Data Solutions**: I work extensively with **AWS** and **Snowflake** to build scalable and cost-efficient architectures.
  - **Machine Learning**: Exploring how to integrate data engineering pipelines with machine learning models for real-time prediction and analysis.

- 🌱 **I’m currently learning**:
  - **Databricks**: Expanding my knowledge in building end-to-end data pipelines and working with Delta Lake.
  - **Advanced Data Warehousing**: Mastering techniques to optimize data storage, retrieval, and transformation for efficient querying.

- 💞️ **I’m looking to collaborate on**:
  - **Open-source projects**: I’m actively looking for opportunities to contribute to projects related to **data engineering**, **cloud platforms**, **real-time data streaming**, and **data science**.
  - **Innovative Data Solutions**: If you’re building something cutting-edge, I’d love to collaborate to improve performance and scalability.

- 📫 **How to reach me**:
  - I’d be happy to connect! You can reach me via:
    - **LinkedIn**: [Rashi Maheshwari](https://www.linkedin.com/in/rashimaheshwari)
    - **Email**: [your-email@example.com]

---

## 💼 A Little About My Work

- I have **3 years** of hands-on experience in **data engineering** roles, optimizing and building **ETL workflows**, **data pipelines**, and **cloud-based data architectures**.
- I’ve contributed to improving **data transformation performance** by **50%** and implemented **cost-optimization strategies** to reduce cloud storage costs.
- With experience in technologies such as **Spark**, **Python**, **SQL**, **Airflow**, and **AWS**, I’m constantly seeking innovative ways to deliver high-performance solutions.

Feel free to browse my repositories, and let’s connect if you’re interested in collaborating or sharing insights on the fascinating world of data engineering!
